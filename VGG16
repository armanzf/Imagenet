import numpy as np 
import pandas as pd 
import glob
import os 
import cv2
from google.colab.patches import cv2_imshow
from tensorflow.keras import utils as np_utils
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import BatchNormalization, GlobalAveragePooling2D
from tensorflow.keras.layers import Activation, Dense, Flatten, BatchNormalization, Conv2D, MaxPool2D
from tensorflow.keras.optimizers import Adam
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
from keras.layers import Dense, Dropout, Flatten, ELU, core


train_path = os.listdir("/content/train/tiny-imagenet-200/train")


Y_train = np.zeros((10000, 1))
X_train = np.zeros((10000, 64, 64, 3))
k=0
for i in train_path:
  
  #print(i)
  path = glob.glob('/content/train/tiny-imagenet-200/train/' + (i) + '/images/')
  #tr_path.append(glob.glob('/content/train/tiny-imagenet-200/train/' + (i) + '/images/'))
  j = 0
  while j<50:
    Y_train[(k*50)+j] = k
    X_train[(k*50)+j, :, :, :] = cv2.imread(path[0] + i + '_'+str(j)+'.JPEG')
    j+=1
  k+=1
  print(k)


### Normalization
for i in range(len(X_train)):
  x = X_train[i, :, :, :]
  x = x/x.max()
  X_train[i, :, :, :] = x


shuffle = list(range(np.size(Y_train, 0)))
np.random.shuffle(shuffle)
x_train = X_train[shuffle, :, :]
y_train = Y_train[shuffle, :]



y_train = np_utils.to_categorical(y_train, 200)

xx_train , xx_test, yy_train, yy_test = train_test_split(x_train, y_train, test_size=0.02, random_state=32)



vgg16_model = tf.keras.applications.vgg16.VGG16(weights="imagenet", include_top=False, input_shape = (64, 64, 3))
vgg16_model.summary()

model= Sequential()
for layer in vgg16_model.layers[:-1]:
  model.add(layer)
  
  
for layer in model.layers:
  layer.trainable = False
#x = model.output
#x = GlobalAveragePooling2D()(x)
#output = Dense (units= 2 , activation = "softmax")(x)
#model (input = model.input , output= output)
model.add (GlobalAveragePooling2D ())
model.add (Dense(units = 200, activation = "softmax"))
model.add(Dropout(0.5))

model.summary()

model.compile(optimizer = Adam(learning_rate =0.0002) , loss = "categorical_crossentropy", metrics = ["accuracy"])

history = model.fit(xx_train, yy_train,
          batch_size=8,
          epochs=60,
          shuffle=True,
          verbose=1,
          validation_split=0.35,
          callbacks=[])
          
          
# Plot the training and validation loss

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Loss vs. epochs')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Training', 'Validation'], loc='upper right')
plt.savefig("fig1.png" , dpi = 200)
plt.show()
#path = "/content/drive/MyDrive/fig/"

#path + 'Klassifikator1.svg', dpi=150




plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Accuracy vs. epochs')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Training', 'Validation'], loc='upper right')
plt.savefig("fig2.png" , dpi = 200)
plt.show()
#path = "/content/drive/MyDrive/fig/"

#path + 'Klassifikator1.svg', dpi=150
